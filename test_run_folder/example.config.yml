# specify the computation chain(s)
chains:

  # data reading
  datachain:
    dataset:
      name: 20newsgroups
      # name: /home/nik/datasets/multiling15/multiling_english_lblratio2mod_oversample.json
      # limit the dataset to a number of documents for train / test: <int>
      data_limit: [400, 200]
      # class_limit: 2
      # mapping_rules:
      #  delete: [hashtag, mention]

  rep:
    link: datachain
    representation:
      name: bag
      #      dimension:
      #name: test
      dimension: 50
      aggregation: avg

  # semantic enrichment

#  sem:
#    link: datachain
#    semantic:
#      name: wordnet
#      unit: concept
#      disambiguation: first
#      weights: frequencies
#
#  fusion:
#    link: [rep, sem]
#    manip:
#      name: concat

  lrn:
    link: [datachain, rep]
    learner:
      name: mlp
      layers: 2
      hidden_dim: 64


# training settings 
train:
  epochs: 10
  # if test data is supplied, trainset is split to folds / val. portion
  # the val. data is used to augment training, if supported by the learning
  # mean performance across folds is reported.
  # if test data is NOT supplied, the validation portion is held out for testing only
  folds: 5
  # validation_portion: 0.1
  early_stopping_patience: 20
  batch_size: 20
  # process samples: oversample or delete
  # sampling_method: oversample
  # desired resulting label ratios.
  # label1_index, label2_index, label1: label2 ratio
  # sampling_ratios: [0,1,2]





print:
  log_level: debug
  # evaluation metrics: f1, accuracy, precision, recall
  measures: ["f1-score"]
  # evaluation metric aggregations: macro, micro, weighted
  label_aggregations: ["macro", "micro"]
  # which run type is of interest
  # run: the actual run you are evaluating
  # majority: a majority classifier baseline
  # random: a random classifier baseline
  run_types: [run]
  # stats aggregating fold values
  fold_aggregations: ["mean", "var"]
  # instance / labelwise error stats
  error_analysis: False
  # training details
  training_progress: True

folders:
  # run folder
  run: test_run_folder
  # folder to store serialization results
  serialization: "serialization"
  # folder to supply raw data, where applicable
  raw_data: raw_data

misc:
  run_id:
  seed: 1337
  keys:
    googleapi: my-google-api-key 
  csv_separator: " "
  deserialization_allowed: True
  model_loading_allowed: False
  prediction_loading_allowed: False
